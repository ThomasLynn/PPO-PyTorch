ppo
15140
1920
6180
10280
DNF (20k)

ppo_2-5
DNF

ppo_6
4320

ppo_7
2220
1760
DNF (20k)
12440
18780
22540

ppo_8
3780

ppo_9
4240
5360

ppo_10
1420
4660
DNF x4 (20k)
1440
4340
DNF x2 (15k)

ppo_11
1980
13880
DNF x3 (20k)

ppo_12
1540
5820
DNF x2 (10k)

ppo_13
DNF x4 (10k)

ppo_15
DNF x3 (5k)

ppo_16
3320
DNF x3 (20k)

ppo_17
1780
2320
2340
7240

ppo_18
DNF (10k)

ppo_19
DNF (10k)

ppo_20
3260
3620
2300
7100

ppo_21
4540
3320
4080
3660
3840
19260
3380
4680
5180
DNF (7k)

ppo_22
740
660
1000
860
660
1080
1060
1560
2460
1680
1860
2400
1420
1000
DNF x3 (10k)

ppo_23 lowered learning rate from 2e-3 to 6e-4
860
780
3240
620
4680
980
620
800
500
860
3100
8340
4840
6200
5020
9360
12700
13480
12860

ppo_24 added minibatches to allow for increased replaybuffer size. increase replay buffer size to 50_000
2800
3080
3740
5360
2620
4000
4280
2420
3160
3600
3180
3540
4420
5240
6300
8340
4840
